{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train XGBoost Model using SageMaker Training + Serve (Host) the Model as a SageMaker Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker import get_execution_role\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import  boto3\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Essentials "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the SageMaker execution role for this notebook and create AWS sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_execution_role = get_execution_role()\n",
    "session = boto3.Session()\n",
    "\n",
    "s3 = session.resource('s3')\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "BUCKET = sagemaker_session.default_bucket()\n",
    "PREFIX = 'clf'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Upload Train & Test Sets to S3 and Create Pointers to Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.create_bucket(Bucket=BUCKET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.Bucket(BUCKET).Object(os.path.join(PREFIX, 'train/train.csv')).upload_file('./DATA/train/train.csv')\n",
    "s3.Bucket(BUCKET).Object(os.path.join(PREFIX, 'test/test.csv')).upload_file('./DATA/test/test.csv')\n",
    "s3.Bucket(BUCKET).Object(os.path.join(PREFIX, 'batch_test/batch_test.csv')).upload_file('./DATA/batch_test/batch_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create Pointers to the uploaded files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_location = 's3://{}/{}/train/'.format(BUCKET, PREFIX)\n",
    "test_set_location = 's3://{}/{}/test/'.format(BUCKET, PREFIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_set_location)\n",
    "print(test_set_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_pointer = TrainingInput(s3_data=train_set_location, content_type='csv', distribution='FullyReplicated')\n",
    "test_set_pointer = TrainingInput(s3_data=test_set_location, content_type='csv', distribution='FullyReplicated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(train_set_pointer.__dict__, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Model using SageMaker + Builtin XgBoost Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container_uri = sagemaker.image_uris.retrieve(region=session.region_name, \n",
    "                                              framework='xgboost', \n",
    "                                              version='1.0-1', \n",
    "                                              image_scope='training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distributed training <br>\n",
    "Distributed training is possible whether or not the data is stored in a single file or multiple files. If itâ€™s stored in a single file, the training computations are distributed across the number of EC2 instances specified by the user.<br> <br>If the data is distributed, SageMaker can handle the data in one of two ways: <br>1) `FullyReplicated` across the number of EC2 instances specified by the user. This leads to slower training times and greater memory consumption, yet it likely produces more accurate models since each EC2 instance is seeing the full training data. <br>2) `ShardedByS3Key`is faster and memory efficient yet slightly less accurate since each EC2 instance only sees a portion of the total training data. For e.g., given 3 EC2 instances forming the disributed compute environment, training data in S3 is split equally across the 3 EC2 instances (i.e. each EC2 sees roughly 1/3rd of the total training data) for fast training times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** When you use `FullyReplicated` mode in distributed setting, the data is copied onto all the machines, however, the training is done using all the machines. Each machine will use part of the data for training and after every batch the weights are synchronized across machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = sagemaker.estimator.Estimator(image_uri=container_uri,\n",
    "                                    role=sagemaker_execution_role, \n",
    "                                    instance_count=2, \n",
    "                                    instance_type='ml.m5.large',\n",
    "                                    output_path='s3://{}/{}/model-artifacts'.format(BUCKET, PREFIX),\n",
    "                                    sagemaker_session=sagemaker_session,\n",
    "                                    base_job_name='classifier')\n",
    "\n",
    "xgb.set_hyperparameters(objective='binary:logistic',\n",
    "                        num_round=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.fit({'train': train_set_pointer, 'validation': test_set_pointer})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Host the Trained Model as a SageMaker Endpoint (using Estimator object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor = xgb.deploy(initial_instance_count=2,\n",
    "                           instance_type='ml.m5.large')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real Time Inference from the Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_serializer = CSVSerializer()\n",
    "predictor = Predictor(endpoint_name=xgb_predictor.endpoint_name, \n",
    "                      serializer=csv_serializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('./DATA/test/test.csv', names=['class', 'bmi', 'diastolic_bp_change', 'systolic_bp_change', 'respiratory_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = test_df.sample(1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.values[0]\n",
    "X[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = X[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "predicted_class_prob = predictor.predict(payload).decode('utf-8')\n",
    "if float(predicted_class_prob) < 0.5:\n",
    "    print('PREDICTION = NOT DIABETIC')\n",
    "else:\n",
    "    print('PREDICTION = DIABETIC')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Hosted Model for Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "expected = []\n",
    "correct = 0\n",
    "for row in test_df.values:\n",
    "    expected_class = row[0]\n",
    "    payload = row[1:]\n",
    "    predicted_class_prob = predictor.predict(payload).decode('utf-8')\n",
    "    predicted_class = 1\n",
    "    if float(predicted_class_prob) < 0.5:\n",
    "        predicted_class = 0  \n",
    "    if predicted_class == expected_class:\n",
    "        correct += 1\n",
    "    predictions.append(predicted_class)\n",
    "    expected.append(expected_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy = {:.2f}%'.format(correct/len(predictions) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected = pd.Series(np.array(expected))\n",
    "predictions = pd.Series(np.array(predictions))\n",
    "pd.crosstab(expected, predictions, rownames=['Actual'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
